{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thirty-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "talented-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the classes that are available in the COCO-Dataset\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regional-coast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /home/sandra.oluoch/.cache/torch/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
      "100%|██████████| 170M/170M [00:02<00:00, 87.8MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign()\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the pretrained model from torchvision.models\n",
    "# Note: pretrained=True will get the pretrained weights for the model.\n",
    "# model.eval() to use the model for inference\n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "established-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating helper functions \n",
    "\n",
    "# fills predicted mask with color\n",
    "def random_colour_masks(image):\n",
    "    \"\"\"\n",
    "    random_colour_masks\n",
    "    parameters:\n",
    "      - image - predicted masks\n",
    "    method:\n",
    "      - the masks of each predicted object is given random colour for visualization\n",
    "    \"\"\"\n",
    "    colours = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180],[250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]\n",
    "    r = np.zeros_like(image).astype(np.uint8)\n",
    "    g = np.zeros_like(image).astype(np.uint8)\n",
    "    b = np.zeros_like(image).astype(np.uint8)\n",
    "    r[image == 1], g[image == 1], b[image == 1] = colours[random.randrange(0,10)]\n",
    "    coloured_mask = np.stack([r, g, b], axis=2)\n",
    "    return coloured_mask\n",
    "\n",
    "# returns the final prediction from the model\n",
    "def get_prediction(img_path, threshold):\n",
    "    \"\"\"\n",
    "    get_prediction\n",
    "    parameters:\n",
    "      - img_path - path of the input image\n",
    "    method:\n",
    "      - Image is obtained from the image path\n",
    "      - the image is converted to image tensor using PyTorch's Transforms\n",
    "      - image is passed through the model to get the predictions\n",
    "      - masks, classes and bounding boxes are obtained from the model and soft masks are made binary(0 or 1) on masks\n",
    "        ie: eg. segment of cat is made 1 and rest of the image is made 0\n",
    "\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    img = transform(img)\n",
    "    pred = model([img])\n",
    "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x>threshold][-1]\n",
    "    masks = (pred[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
    "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
    "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n",
    "    masks = masks[:pred_t+1]\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    return masks, pred_boxes, pred_class\n",
    "\n",
    "# overlays colored mask over original image \n",
    "def instance_segmentation_api(img_path, threshold=0.5, rect_th=3, text_size=3, text_th=3):\n",
    "    \"\"\"\n",
    "    instance_segmentation_api\n",
    "    parameters:\n",
    "      - img_path - path to input image\n",
    "    method:\n",
    "      - prediction is obtained by get_prediction\n",
    "      - each mask is given random color\n",
    "      - each mask is added to the image in the ration 1:0.8 with opencv\n",
    "      - final output is displayed\n",
    "    \"\"\"\n",
    "    masks, boxes, pred_cls = get_prediction(img_path, threshold)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    for i in range(len(masks)):\n",
    "        rgb_mask = random_colour_masks(masks[i])\n",
    "        img = cv2.addWeighted(img, 1, rgb_mask, 0.5, 0)\n",
    "        cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(0, 255, 0), thickness=rect_th)\n",
    "        cv2.putText(img,pred_cls[i], boxes[i][0], cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th)\n",
    "    plt.figure(figsize=(20,30))\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stylish-exclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the image and plotting it\n",
    "\n",
    "img = Image.open(\"//allen/aics/microscopy/Ellen/RNA FISH/20230427_inhouse_beads_150K/20230427_inhouse_beads_150K/1/mFISH__004/0Processed Images/1-Pos_003_000_Composite_MIP.tif\")\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stopped-security",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2048, 2048, 5]' is invalid for input of size 8388608",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-45c1d7ec6f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Running inference on the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/allen/aics/apps/hpc_shared/mod/anaconda3-5.3.0/envs/tracking_analysis_morph/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/allen/aics/apps/hpc_shared/mod/anaconda3-5.3.0/envs/tracking_analysis_morph/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/allen/aics/apps/hpc_shared/mod/anaconda3-5.3.0/envs/tracking_analysis_morph/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2048, 2048, 5]' is invalid for input of size 8388608"
     ]
    }
   ],
   "source": [
    "# Running inference on the image\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "img_tensor = transform(img)\n",
    "pred = model([img_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-killer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
